{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>boss bag award executive business magazine tit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>copy bumper sale fi shooter game copy sale com...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>msp climate warning climate change control dec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pavey success view week race track bronze inju...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tory rethink association candidate election ag...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  boss bag award executive business magazine tit...      0\n",
       "1  copy bumper sale fi shooter game copy sale com...      4\n",
       "2  msp climate warning climate change control dec...      2\n",
       "3  pavey success view week race track bronze inju...      3\n",
       "4  tory rethink association candidate election ag...      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "DATA_DIR = \"./bbc/\"\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\", random_state=random_state)\n",
    "df = pd.DataFrame(list(zip(data['data'], data['target'])), columns=['text', 'label'])\n",
    "\n",
    "def only_nouns(texts):\n",
    "    output = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        noun_text = \" \".join(token.lemma_ for token in doc if token.pos_ == 'NOUN')\n",
    "        output.append(noun_text)\n",
    "    return output\n",
    "\n",
    "\n",
    "df['text'] = only_nouns(df['text'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=5, random_state=0, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of topics to extract\n",
    "n_topics = 5\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vec = TfidfVectorizer(max_features=5000, stop_words=\"english\", max_df=0.95, min_df=2)\n",
    "features = vec.fit_transform(df.text)\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "cls = NMF(n_components=n_topics, random_state=random_state)\n",
    "cls.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 growth sale economy year company market share rate price firm profit oil analyst month quarter \n",
      "1 film award actor star actress director nomination movie year comedy role festival prize category ceremony \n",
      "2 game player match team injury club time win season coach goal victory title champion half \n",
      "3 election party government tax minister leader people campaign chancellor plan issue voter country taxis vote \n",
      "4 phone people music technology service user broadband software computer tv network device video site mobile \n"
     ]
    }
   ],
   "source": [
    "# list of unique words found by the vectorizer\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "# number of most influencing words to display per topic\n",
    "n_top_words = 15\n",
    "\n",
    "for i, topic_vec in enumerate(cls.components_):\n",
    "    print(i, end=' ')\n",
    "    # topic_vec.argsort() produces a new array\n",
    "    # in which word_index with the least score is the\n",
    "    # first array element and word_index with highest\n",
    "    # score is the last array element. Then using a\n",
    "    # fancy indexing [-1: -n_top_words-1:-1], we are\n",
    "    # slicing the array from its end in such a way that\n",
    "    # top `n_top_words` word_index with highest scores\n",
    "    # are returned in desceding order\n",
    "    for fid in topic_vec.argsort()[-1:-n_top_words-1:-1]:\n",
    "        print(feature_names[fid], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identyfying the topic of a new text\n",
    "new_articles = [\n",
    "    \"Playstation network was down so many people were angry\",\n",
    "    \"Germany scored 7 goals against Brazil in worldcup semi-finals\"\n",
    "]\n",
    "# first transform the text into features using vec\n",
    "# then pass it to transform of cls\n",
    "# the result will be a matrix of shape [2, 10]\n",
    "# then we sort the topic id based on the score using argsort\n",
    "# and take the last one (with the highest score) for each row using `[:,-1]` indexing\n",
    "cls.transform(vec.transform(new_articles)).argsort(axis=1)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
